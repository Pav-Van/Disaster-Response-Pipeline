{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\phewv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\phewv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\phewv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\phewv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import joblib\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql_table('DisasterResponse',engine)\n",
    "X = df.message.values\n",
    "y = df.drop(columns=df.columns[0:4],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    tokens = [WordNetLemmatizer().lemmatize(w).strip() for w in tokens if w not in stopwords.words(\"english\")]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(estimator=MultinomialNB()))\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function tokenize at 0x000001E1D3ADF520&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultiOutputClassifier(estimator=MultinomialNB()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function tokenize at 0x000001E1D3ADF520&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultiOutputClassifier(estimator=MultinomialNB()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function tokenize at 0x000001E1D3ADF520&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=MultinomialNB())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x000001E1D3ADF520>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultiOutputClassifier(estimator=MultinomialNB()))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.3)\n",
    "pipeline.fit(X_train , y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.10      0.17      1841\n",
      "           1       0.77      0.99      0.87      5956\n",
      "\n",
      "   micro avg       0.77      0.78      0.78      7797\n",
      "   macro avg       0.79      0.54      0.52      7797\n",
      "weighted avg       0.78      0.78      0.70      7797\n",
      "\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      6573\n",
      "           1       0.86      0.22      0.35      1292\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.86      0.61      0.64      7865\n",
      "weighted avg       0.86      0.87      0.83      7865\n",
      "\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7821\n",
      "\n",
      "   micro avg       0.99      1.00      1.00      7821\n",
      "   macro avg       0.99      1.00      1.00      7821\n",
      "weighted avg       0.99      1.00      1.00      7821\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.80      4647\n",
      "           1       0.72      0.63      0.67      3218\n",
      "\n",
      "    accuracy                           0.75      7865\n",
      "   macro avg       0.74      0.73      0.74      7865\n",
      "weighted avg       0.75      0.75      0.75      7865\n",
      "\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7237\n",
      "           1       0.00      0.00      0.00       628\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.46      0.50      0.48      7865\n",
      "weighted avg       0.85      0.92      0.88      7865\n",
      "\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7484\n",
      "\n",
      "   micro avg       0.95      1.00      0.98      7484\n",
      "   macro avg       0.95      1.00      0.98      7484\n",
      "weighted avg       0.95      1.00      0.98      7484\n",
      "\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7660\n",
      "\n",
      "   micro avg       0.97      1.00      0.99      7660\n",
      "   macro avg       0.97      1.00      0.99      7660\n",
      "weighted avg       0.97      1.00      0.99      7660\n",
      "\n",
      "6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7732\n",
      "\n",
      "   micro avg       0.98      1.00      0.99      7732\n",
      "   macro avg       0.98      1.00      0.99      7732\n",
      "weighted avg       0.98      1.00      0.99      7732\n",
      "\n",
      "7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7609\n",
      "\n",
      "   micro avg       0.97      1.00      0.98      7609\n",
      "   macro avg       0.97      1.00      0.98      7609\n",
      "weighted avg       0.97      1.00      0.98      7609\n",
      "\n",
      "8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7865\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       1.00      1.00      1.00      7865\n",
      "weighted avg       1.00      1.00      1.00      7865\n",
      "\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7402\n",
      "\n",
      "   micro avg       0.94      1.00      0.97      7402\n",
      "   macro avg       0.94      1.00      0.97      7402\n",
      "weighted avg       0.94      1.00      0.97      7402\n",
      "\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7004\n",
      "           1       0.71      0.02      0.04       861\n",
      "\n",
      "    accuracy                           0.89      7865\n",
      "   macro avg       0.80      0.51      0.49      7865\n",
      "weighted avg       0.87      0.89      0.84      7865\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7180\n",
      "           1       0.00      0.00      0.00       685\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.46      0.50      0.48      7865\n",
      "weighted avg       0.83      0.91      0.87      7865\n",
      "\n",
      "12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7748\n",
      "\n",
      "   micro avg       0.99      1.00      0.99      7748\n",
      "   macro avg       0.99      1.00      0.99      7748\n",
      "weighted avg       0.99      1.00      0.99      7748\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7680\n",
      "\n",
      "   micro avg       0.98      1.00      0.99      7680\n",
      "   macro avg       0.98      1.00      0.99      7680\n",
      "weighted avg       0.98      1.00      0.99      7680\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7769\n",
      "\n",
      "   micro avg       0.99      1.00      0.99      7769\n",
      "   macro avg       0.99      1.00      0.99      7769\n",
      "weighted avg       0.99      1.00      0.99      7769\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7599\n",
      "\n",
      "   micro avg       0.97      1.00      0.98      7599\n",
      "   macro avg       0.97      1.00      0.98      7599\n",
      "weighted avg       0.97      1.00      0.98      7599\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7510\n",
      "\n",
      "   micro avg       0.95      1.00      0.98      7510\n",
      "   macro avg       0.95      1.00      0.98      7510\n",
      "weighted avg       0.95      1.00      0.98      7510\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      6855\n",
      "           1       0.00      0.00      0.00      1010\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.44      0.50      0.47      7865\n",
      "weighted avg       0.76      0.87      0.81      7865\n",
      "\n",
      "18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7356\n",
      "\n",
      "   micro avg       0.94      1.00      0.97      7356\n",
      "   macro avg       0.94      1.00      0.97      7356\n",
      "weighted avg       0.94      1.00      0.97      7356\n",
      "\n",
      "19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7517\n",
      "\n",
      "   micro avg       0.96      1.00      0.98      7517\n",
      "   macro avg       0.96      1.00      0.98      7517\n",
      "weighted avg       0.96      1.00      0.98      7517\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7483\n",
      "\n",
      "   micro avg       0.95      1.00      0.98      7483\n",
      "   macro avg       0.95      1.00      0.98      7483\n",
      "weighted avg       0.95      1.00      0.98      7483\n",
      "\n",
      "21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7714\n",
      "\n",
      "   micro avg       0.98      1.00      0.99      7714\n",
      "   macro avg       0.98      1.00      0.99      7714\n",
      "weighted avg       0.98      1.00      0.99      7714\n",
      "\n",
      "22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7820\n",
      "\n",
      "   micro avg       0.99      1.00      1.00      7820\n",
      "   macro avg       0.99      1.00      1.00      7820\n",
      "weighted avg       0.99      1.00      1.00      7820\n",
      "\n",
      "23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7774\n",
      "\n",
      "   micro avg       0.99      1.00      0.99      7774\n",
      "   macro avg       0.99      1.00      0.99      7774\n",
      "weighted avg       0.99      1.00      0.99      7774\n",
      "\n",
      "24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7823\n",
      "\n",
      "   micro avg       0.99      1.00      1.00      7823\n",
      "   macro avg       0.99      1.00      1.00      7823\n",
      "weighted avg       0.99      1.00      1.00      7823\n",
      "\n",
      "25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7779\n",
      "\n",
      "   micro avg       0.99      1.00      0.99      7779\n",
      "   macro avg       0.99      1.00      0.99      7779\n",
      "weighted avg       0.99      1.00      0.99      7779\n",
      "\n",
      "26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7523\n",
      "\n",
      "   micro avg       0.96      1.00      0.98      7523\n",
      "   macro avg       0.96      1.00      0.98      7523\n",
      "weighted avg       0.96      1.00      0.98      7523\n",
      "\n",
      "27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88      5652\n",
      "           1       0.83      0.40      0.54      2213\n",
      "\n",
      "    accuracy                           0.81      7865\n",
      "   macro avg       0.82      0.68      0.71      7865\n",
      "weighted avg       0.81      0.81      0.78      7865\n",
      "\n",
      "28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7211\n",
      "           1       0.60      0.00      0.01       654\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.76      0.50      0.48      7865\n",
      "weighted avg       0.89      0.92      0.88      7865\n",
      "\n",
      "29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7109\n",
      "           1       0.67      0.01      0.03       756\n",
      "\n",
      "    accuracy                           0.90      7865\n",
      "   macro avg       0.79      0.51      0.49      7865\n",
      "weighted avg       0.88      0.90      0.86      7865\n",
      "\n",
      "30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7783\n",
      "\n",
      "   micro avg       0.99      1.00      0.99      7783\n",
      "   macro avg       0.99      1.00      0.99      7783\n",
      "weighted avg       0.99      1.00      0.99      7783\n",
      "\n",
      "31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7131\n",
      "           1       0.88      0.10      0.18       734\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.90      0.55      0.57      7865\n",
      "weighted avg       0.91      0.91      0.88      7865\n",
      "\n",
      "32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7696\n",
      "\n",
      "   micro avg       0.98      1.00      0.99      7696\n",
      "   macro avg       0.98      1.00      0.99      7696\n",
      "weighted avg       0.98      1.00      0.99      7696\n",
      "\n",
      "33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7438\n",
      "\n",
      "   micro avg       0.95      1.00      0.97      7438\n",
      "   macro avg       0.95      1.00      0.97      7438\n",
      "weighted avg       0.95      1.00      0.97      7438\n",
      "\n",
      "34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90      6350\n",
      "           1       0.81      0.16      0.26      1515\n",
      "\n",
      "    accuracy                           0.83      7865\n",
      "   macro avg       0.82      0.57      0.58      7865\n",
      "weighted avg       0.83      0.83      0.78      7865\n",
      "\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "for col in range(y_pred.shape[1]):\n",
    "\n",
    "    print(classification_report(y_test.iloc[:,col],y_pred[:,col],labels=np.unique(y_pred[:,col])))\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(tokenizer=<function tokenize at 0x000001E1D3ADF520>)),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('clf', MultiOutputClassifier(estimator=MultinomialNB()))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(tokenizer=<function tokenize at 0x000001E1D3ADF520>),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'clf': MultiOutputClassifier(estimator=MultinomialNB()),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__alpha': 1.0,\n",
       " 'clf__estimator__class_prior': None,\n",
       " 'clf__estimator__fit_prior': True,\n",
       " 'clf__estimator__force_alpha': 'warn',\n",
       " 'clf__estimator': MultinomialNB(),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m parameters \u001b[39m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mclf__estimator__alpha\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.1\u001b[39m, \u001b[39m0.5\u001b[39m]\n\u001b[0;32m      4\u001b[0m        \n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      7\u001b[0m cv \u001b[39m=\u001b[39m GridSearchCV(pipeline,param_grid\u001b[39m=\u001b[39mparameters)\n\u001b[1;32m----> 9\u001b[0m cv\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1048\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1380\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m             )\n\u001b[0;32m   1385\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1390\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1274\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   1273\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1275\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m     doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     doc \u001b[39m=\u001b[39m tokenizer(doc)\n\u001b[0;32m    114\u001b[0m \u001b[39mif\u001b[39;00m ngrams \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m     \u001b[39mif\u001b[39;00m stop_words \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[^a-zA-Z0-9]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, text\u001b[39m.\u001b[39mlower())\n\u001b[0;32m      5\u001b[0m tokens \u001b[39m=\u001b[39m word_tokenize(text)\n\u001b[1;32m----> 7\u001b[0m tokens \u001b[39m=\u001b[39m [WordNetLemmatizer()\u001b[39m.\u001b[39mlemmatize(w)\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m w \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39mwords(\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m tokens\n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[^a-zA-Z0-9]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, text\u001b[39m.\u001b[39mlower())\n\u001b[0;32m      5\u001b[0m tokens \u001b[39m=\u001b[39m word_tokenize(text)\n\u001b[1;32m----> 7\u001b[0m tokens \u001b[39m=\u001b[39m [WordNetLemmatizer()\u001b[39m.\u001b[39mlemmatize(w)\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m w \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m\"\u001b[39;49m\u001b[39menglish\u001b[39;49m\u001b[39m\"\u001b[39;49m)]\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m tokens\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwords\u001b[39m(\u001b[39mself\u001b[39m, fileids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ignore_lines_startswith\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m line_tokenize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw(fileids))\n\u001b[0;32m     22\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[39m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen(f) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[39m.\u001b[39mappend(fp\u001b[39m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[39mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root\u001b[39m.\u001b[39;49mjoin(file)\u001b[39m.\u001b[39;49mopen(encoding)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\nltk\\data.py:324\u001b[0m, in \u001b[0;36mFileSystemPathPointer.open\u001b[1;34m(self, encoding)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 324\u001b[0m     stream \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    325\u001b[0m     \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         stream \u001b[39m=\u001b[39m SeekableUnicodeStreamReader(stream, encoding)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "\n",
    "    'clf__estimator__alpha': [0.1, 0.5]\n",
    "       \n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline,param_grid=parameters)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'clf__estimator__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Parameters:\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.37      0.49      1874\n",
      "           1       0.82      0.95      0.88      5934\n",
      "           2       0.74      0.30      0.42        57\n",
      "\n",
      "    accuracy                           0.81      7865\n",
      "   macro avg       0.76      0.54      0.60      7865\n",
      "weighted avg       0.80      0.81      0.79      7865\n",
      "\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93      6478\n",
      "           1       0.71      0.53      0.61      1387\n",
      "\n",
      "    accuracy                           0.88      7865\n",
      "   macro avg       0.81      0.74      0.77      7865\n",
      "weighted avg       0.87      0.88      0.87      7865\n",
      "\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7831\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      4607\n",
      "           1       0.69      0.68      0.68      3258\n",
      "\n",
      "    accuracy                           0.74      7865\n",
      "   macro avg       0.73      0.73      0.73      7865\n",
      "weighted avg       0.74      0.74      0.74      7865\n",
      "\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7212\n",
      "           1       0.54      0.14      0.22       653\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.73      0.56      0.59      7865\n",
      "weighted avg       0.89      0.92      0.90      7865\n",
      "\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7468\n",
      "           1       0.67      0.15      0.24       397\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.81      0.57      0.61      7865\n",
      "weighted avg       0.94      0.95      0.94      7865\n",
      "\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7642\n",
      "           1       0.43      0.01      0.03       223\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.70      0.51      0.51      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7730\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      7604\n",
      "           1       0.57      0.21      0.30       261\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.77      0.60      0.64      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7865\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       1.00      1.00      1.00      7865\n",
      "weighted avg       1.00      1.00      1.00      7865\n",
      "\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      7330\n",
      "           1       0.56      0.10      0.17       535\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.75      0.55      0.57      7865\n",
      "weighted avg       0.91      0.93      0.91      7865\n",
      "\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      6978\n",
      "           1       0.71      0.32      0.44       887\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.81      0.65      0.69      7865\n",
      "weighted avg       0.89      0.91      0.89      7865\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7176\n",
      "           1       0.67      0.17      0.27       689\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.80      0.58      0.61      7865\n",
      "weighted avg       0.90      0.92      0.90      7865\n",
      "\n",
      "12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7747\n",
      "           1       0.74      0.14      0.24       118\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.86      0.57      0.62      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7664\n",
      "           1       0.00      0.00      0.00       201\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.95      0.97      0.96      7865\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7772\n",
      "           1       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7601\n",
      "           1       0.25      0.01      0.01       264\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.61      0.50      0.50      7865\n",
      "weighted avg       0.94      0.97      0.95      7865\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7505\n",
      "           1       0.71      0.13      0.22       360\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.83      0.57      0.60      7865\n",
      "weighted avg       0.95      0.96      0.94      7865\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      6843\n",
      "           1       0.41      0.03      0.05      1022\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.64      0.51      0.49      7865\n",
      "weighted avg       0.81      0.87      0.82      7865\n",
      "\n",
      "18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7370\n",
      "           1       0.10      0.01      0.01       495\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.52      0.50      0.49      7865\n",
      "weighted avg       0.88      0.93      0.91      7865\n",
      "\n",
      "19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7504\n",
      "           1       0.56      0.06      0.11       361\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.76      0.53      0.54      7865\n",
      "weighted avg       0.94      0.95      0.94      7865\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7476\n",
      "           1       0.44      0.04      0.07       389\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.70      0.52      0.52      7865\n",
      "weighted avg       0.93      0.95      0.93      7865\n",
      "\n",
      "21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7702\n",
      "           1       0.50      0.02      0.04       163\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.74      0.51      0.51      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7818\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7773\n",
      "           1       0.00      0.00      0.00        92\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7837\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7776\n",
      "           1       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7522\n",
      "           1       0.00      0.00      0.00       343\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.91      0.95      0.93      7865\n",
      "\n",
      "27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      5717\n",
      "           1       0.73      0.59      0.65      2148\n",
      "\n",
      "    accuracy                           0.83      7865\n",
      "   macro avg       0.80      0.75      0.77      7865\n",
      "weighted avg       0.82      0.83      0.82      7865\n",
      "\n",
      "28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      7244\n",
      "           1       0.69      0.30      0.42       621\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.82      0.64      0.69      7865\n",
      "weighted avg       0.92      0.93      0.92      7865\n",
      "\n",
      "29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7102\n",
      "           1       0.73      0.34      0.46       763\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.83      0.66      0.71      7865\n",
      "weighted avg       0.91      0.92      0.91      7865\n",
      "\n",
      "30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7782\n",
      "           1       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      7154\n",
      "           1       0.80      0.39      0.52       711\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.87      0.69      0.74      7865\n",
      "weighted avg       0.93      0.94      0.93      7865\n",
      "\n",
      "32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7722\n",
      "           1       0.50      0.03      0.05       143\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.74      0.51      0.52      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7448\n",
      "           1       0.45      0.03      0.06       417\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.70      0.51      0.52      7865\n",
      "weighted avg       0.92      0.95      0.92      7865\n",
      "\n",
      "34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      6332\n",
      "           1       0.67      0.49      0.56      1533\n",
      "\n",
      "    accuracy                           0.85      7865\n",
      "   macro avg       0.78      0.71      0.74      7865\n",
      "weighted avg       0.84      0.85      0.84      7865\n",
      "\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "pipeline_tuned = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(estimator=MultinomialNB(alpha=0.1)))\n",
    "])\n",
    "\n",
    "pipeline_tuned.fit(X_train , y_train)\n",
    "y_pred_tuned = pipeline_tuned.predict(X_test)\n",
    "\n",
    "for col in range(y_pred_tuned.shape[1]):\n",
    "\n",
    "    print(classification_report(y_test.iloc[:,col],y_pred_tuned[:,col],labels=np.unique(y_pred_tuned[:,col])))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related                   14190\n",
      "request                    3182\n",
      "offer                        74\n",
      "aid_related                7642\n",
      "medical_help               1456\n",
      "medical_products            932\n",
      "search_and_rescue           519\n",
      "security                    338\n",
      "military                    604\n",
      "child_alone                   0\n",
      "water                      1209\n",
      "food                       2062\n",
      "shelter                    1629\n",
      "clothing                    288\n",
      "money                       419\n",
      "missing_people              202\n",
      "refugees                    609\n",
      "death                       839\n",
      "other_aid                  2436\n",
      "infrastructure_related     1196\n",
      "transport                   853\n",
      "buildings                   951\n",
      "electricity                 381\n",
      "tools                       114\n",
      "hospitals                   192\n",
      "shops                        78\n",
      "aid_centers                 223\n",
      "other_infrastructure        809\n",
      "weather_related            5084\n",
      "floods                     1501\n",
      "storm                      1687\n",
      "fire                        200\n",
      "earthquake                 1721\n",
      "cold                        361\n",
      "other_weather               949\n",
      "direct_report              3560\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'water', 'food', 'shelter', 'clothing', 'money', 'missing_people',\n",
       "       'refugees', 'death', 'other_aid', 'infrastructure_related', 'transport',\n",
       "       'buildings', 'electricity', 'tools', 'hospitals', 'shops',\n",
       "       'aid_centers', 'other_infrastructure', 'weather_related', 'floods',\n",
       "       'storm', 'fire', 'earthquake', 'cold', 'other_weather',\n",
       "       'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#See which column has all 0 values\n",
    "print(y_train.sum())\n",
    "\n",
    "#remove the column that has all 0 values\n",
    "y_train_test = y_train.drop(labels=['child_alone'],axis=1)\n",
    "y_train_test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.related.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.45      0.55      1841\n",
      "           1       0.84      0.95      0.89      5956\n",
      "           2       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.82      7865\n",
      "   macro avg       0.52      0.46      0.48      7865\n",
      "weighted avg       0.80      0.82      0.80      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      6573\n",
      "           1       0.81      0.52      0.63      1292\n",
      "\n",
      "    accuracy                           0.90      7865\n",
      "   macro avg       0.86      0.75      0.79      7865\n",
      "weighted avg       0.89      0.90      0.89      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7821\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      4647\n",
      "           1       0.76      0.66      0.71      3218\n",
      "\n",
      "    accuracy                           0.78      7865\n",
      "   macro avg       0.77      0.76      0.76      7865\n",
      "weighted avg       0.77      0.78      0.77      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7237\n",
      "           1       0.61      0.15      0.24       628\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.77      0.57      0.60      7865\n",
      "weighted avg       0.91      0.92      0.90      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7484\n",
      "           1       0.71      0.14      0.24       381\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.83      0.57      0.61      7865\n",
      "weighted avg       0.95      0.96      0.94      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7660\n",
      "           1       0.90      0.04      0.08       205\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.94      0.52      0.54      7865\n",
      "weighted avg       0.97      0.97      0.96      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7732\n",
      "           1       0.00      0.00      0.00       133\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7609\n",
      "           1       0.56      0.08      0.14       256\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.76      0.54      0.56      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      7865\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.50      0.48      0.49      7865\n",
      "weighted avg       1.00      0.97      0.98      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      7402\n",
      "           1       0.30      0.38      0.34       463\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.63      0.66      0.64      7865\n",
      "weighted avg       0.92      0.91      0.92      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      7004\n",
      "           1       0.34      0.14      0.20       861\n",
      "\n",
      "    accuracy                           0.88      7865\n",
      "   macro avg       0.62      0.55      0.57      7865\n",
      "weighted avg       0.84      0.88      0.85      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7180\n",
      "           1       0.21      0.01      0.02       685\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.56      0.50      0.49      7865\n",
      "weighted avg       0.85      0.91      0.87      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7748\n",
      "           1       0.00      0.00      0.00       117\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.98      0.98      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7680\n",
      "           1       0.00      0.00      0.00       185\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.95      0.98      0.96      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7769\n",
      "           1       0.04      0.01      0.02        96\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.52      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      7599\n",
      "           1       0.10      0.04      0.06       266\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.53      0.51      0.52      7865\n",
      "weighted avg       0.94      0.96      0.95      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      7510\n",
      "           1       0.05      0.03      0.03       355\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.91      0.93      0.92      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      6855\n",
      "           1       0.28      0.01      0.02      1010\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.57      0.50      0.47      7865\n",
      "weighted avg       0.80      0.87      0.81      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      7356\n",
      "           1       0.22      0.02      0.04       509\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.58      0.51      0.50      7865\n",
      "weighted avg       0.89      0.93      0.90      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      7517\n",
      "           1       0.11      0.04      0.06       348\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.53      0.51      0.51      7865\n",
      "weighted avg       0.92      0.94      0.93      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7483\n",
      "           1       0.10      0.01      0.01       382\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.52      0.50      0.49      7865\n",
      "weighted avg       0.91      0.95      0.93      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7714\n",
      "           1       0.00      0.00      0.00       151\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7820\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7774\n",
      "           1       0.00      0.00      0.00        91\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7823\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7779\n",
      "           1       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88      7523\n",
      "           1       0.10      0.47      0.16       342\n",
      "\n",
      "    accuracy                           0.79      7865\n",
      "   macro avg       0.53      0.63      0.52      7865\n",
      "weighted avg       0.93      0.79      0.85      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85      5652\n",
      "           1       0.94      0.12      0.21      2213\n",
      "\n",
      "    accuracy                           0.75      7865\n",
      "   macro avg       0.84      0.56      0.53      7865\n",
      "weighted avg       0.80      0.75      0.67      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      7211\n",
      "           1       0.22      0.15      0.18       654\n",
      "\n",
      "    accuracy                           0.89      7865\n",
      "   macro avg       0.57      0.55      0.56      7865\n",
      "weighted avg       0.87      0.89      0.88      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7109\n",
      "           1       0.00      0.00      0.00       756\n",
      "\n",
      "    accuracy                           0.90      7865\n",
      "   macro avg       0.45      0.50      0.47      7865\n",
      "weighted avg       0.82      0.90      0.86      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      7783\n",
      "           1       0.01      0.10      0.03        82\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.50      0.51      0.49      7865\n",
      "weighted avg       0.98      0.92      0.95      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7131\n",
      "           1       0.23      0.01      0.01       734\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.57      0.50      0.48      7865\n",
      "weighted avg       0.84      0.91      0.86      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7696\n",
      "           1       0.26      0.04      0.07       169\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.62      0.52      0.53      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      7438\n",
      "           1       0.05      0.09      0.06       427\n",
      "\n",
      "    accuracy                           0.85      7865\n",
      "   macro avg       0.50      0.49      0.49      7865\n",
      "weighted avg       0.90      0.85      0.87      7865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipeline_log = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(estimator=LogisticRegression()))\n",
    "]) \n",
    "\n",
    "pipeline_log.fit(X_train , y_train_test)\n",
    "y_pred_SVC = pipeline_log.predict(X_test)\n",
    "\n",
    "for col in range(y_pred_SVC.shape[1]):\n",
    "\n",
    "    print(classification_report(y_test.iloc[:,col],y_pred_SVC[:,col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.07      0.12      1874\n",
      "           1       0.77      0.99      0.87      5934\n",
      "           2       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.77      7865\n",
      "   macro avg       0.52      0.35      0.33      7865\n",
      "weighted avg       0.77      0.77      0.68      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      6478\n",
      "           1       0.91      0.33      0.48      1387\n",
      "\n",
      "    accuracy                           0.88      7865\n",
      "   macro avg       0.89      0.66      0.71      7865\n",
      "weighted avg       0.88      0.88      0.85      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7831\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.80      4607\n",
      "           1       0.84      0.43      0.56      3258\n",
      "\n",
      "    accuracy                           0.73      7865\n",
      "   macro avg       0.77      0.68      0.68      7865\n",
      "weighted avg       0.76      0.73      0.70      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7212\n",
      "           1       0.00      0.00      0.00       653\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.46      0.50      0.48      7865\n",
      "weighted avg       0.84      0.92      0.88      7865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7468\n",
      "           1       0.00      0.00      0.00       397\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.47      0.50      0.49      7865\n",
      "weighted avg       0.90      0.95      0.92      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7642\n",
      "           1       0.00      0.00      0.00       223\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.94      0.97      0.96      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7730\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7604\n",
      "           1       0.00      0.00      0.00       261\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.93      0.97      0.95      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      7865\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       1.00      0.99      1.00      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      7330\n",
      "           1       0.31      0.30      0.30       535\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.63      0.62      0.63      7865\n",
      "weighted avg       0.91      0.91      0.91      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6978\n",
      "           1       0.38      0.06      0.10       887\n",
      "\n",
      "    accuracy                           0.88      7865\n",
      "   macro avg       0.63      0.52      0.52      7865\n",
      "weighted avg       0.83      0.88      0.84      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7176\n",
      "           1       0.00      0.00      0.00       689\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.46      0.50      0.48      7865\n",
      "weighted avg       0.83      0.91      0.87      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7747\n",
      "           1       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.98      0.98      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7664\n",
      "           1       0.00      0.00      0.00       201\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.95      0.97      0.96      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7772\n",
      "           1       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7601\n",
      "           1       0.00      0.00      0.00       264\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.93      0.97      0.95      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7505\n",
      "           1       0.00      0.00      0.00       360\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.91      0.95      0.93      7865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      6843\n",
      "           1       0.00      0.00      0.00      1022\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.44      0.50      0.47      7865\n",
      "weighted avg       0.76      0.87      0.81      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7370\n",
      "           1       0.00      0.00      0.00       495\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.47      0.50      0.48      7865\n",
      "weighted avg       0.88      0.94      0.91      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7504\n",
      "           1       0.00      0.00      0.00       361\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.91      0.95      0.93      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7476\n",
      "           1       0.00      0.00      0.00       389\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.90      0.95      0.93      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7702\n",
      "           1       0.00      0.00      0.00       163\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7818\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7773\n",
      "           1       0.00      0.00      0.00        92\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7837\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7776\n",
      "           1       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      7522\n",
      "           1       0.08      0.22      0.12       343\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.52      0.55      0.52      7865\n",
      "weighted avg       0.92      0.86      0.89      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84      5717\n",
      "           1       0.96      0.02      0.04      2148\n",
      "\n",
      "    accuracy                           0.73      7865\n",
      "   macro avg       0.84      0.51      0.44      7865\n",
      "weighted avg       0.79      0.73      0.62      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      7244\n",
      "           1       0.05      0.00      0.01       621\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.49      0.50      0.48      7865\n",
      "weighted avg       0.85      0.91      0.88      7865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\phewv\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7102\n",
      "           1       0.00      0.00      0.00       763\n",
      "\n",
      "    accuracy                           0.90      7865\n",
      "   macro avg       0.45      0.50      0.47      7865\n",
      "weighted avg       0.82      0.90      0.86      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      7782\n",
      "           1       0.01      0.04      0.01        83\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.50      0.49      0.49      7865\n",
      "weighted avg       0.98      0.94      0.96      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7154\n",
      "           1       0.00      0.00      0.00       711\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.45      0.50      0.48      7865\n",
      "weighted avg       0.83      0.91      0.87      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7722\n",
      "           1       0.00      0.00      0.00       143\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      7448\n",
      "           1       0.04      0.03      0.03       417\n",
      "\n",
      "    accuracy                           0.90      7865\n",
      "   macro avg       0.49      0.49      0.49      7865\n",
      "weighted avg       0.90      0.90      0.90      7865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_SVC = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(estimator=SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)))\n",
    "]) \n",
    "\n",
    "pipeline_SVC.fit(X_train , y_train_test)\n",
    "y_pred_SVC = pipeline_SVC.predict(X_test)\n",
    "\n",
    "for col in range(y_pred_SVC.shape[1]):\n",
    "\n",
    "    print(classification_report(y_test.iloc[:,col],y_pred_SVC[:,col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pipeline_Log.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline_log, 'Pipeline_Log.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
