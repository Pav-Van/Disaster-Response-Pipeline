{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LocalAdmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LocalAdmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LocalAdmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\LocalAdmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///MessagesDB.db')\n",
    "df = pd.read_sql_table('MessagesDB',engine)\n",
    "X = df.message.values\n",
    "y = df.drop(columns=df.columns[0:4],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    tokens = [WordNetLemmatizer().lemmatize(w).strip() for w in tokens if w not in stopwords.words(\"english\")]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(estimator=MultinomialNB()))\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function tokenize at 0x00000221C47A9090&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultiOutputClassifier(estimator=MultinomialNB()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function tokenize at 0x00000221C47A9090&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultiOutputClassifier(estimator=MultinomialNB()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function tokenize at 0x00000221C47A9090&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=MultinomialNB())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x00000221C47A9090>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultiOutputClassifier(estimator=MultinomialNB()))])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.3)\n",
    "pipeline.fit(X_train , y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.10      0.17      1844\n",
      "           1       0.78      0.99      0.87      5966\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      7810\n",
      "   macro avg       0.78      0.54      0.52      7810\n",
      "weighted avg       0.78      0.78      0.71      7810\n",
      "\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      6488\n",
      "           1       0.87      0.21      0.34      1377\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.86      0.60      0.63      7865\n",
      "weighted avg       0.86      0.86      0.82      7865\n",
      "\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7838\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      7838\n",
      "   macro avg       1.00      1.00      1.00      7838\n",
      "weighted avg       1.00      1.00      1.00      7838\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80      4595\n",
      "           1       0.74      0.61      0.67      3270\n",
      "\n",
      "    accuracy                           0.75      7865\n",
      "   macro avg       0.75      0.73      0.73      7865\n",
      "weighted avg       0.75      0.75      0.74      7865\n",
      "\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7239\n",
      "           1       1.00      0.00      0.00       626\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.96      0.50      0.48      7865\n",
      "weighted avg       0.93      0.92      0.88      7865\n",
      "\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7494\n",
      "           1       0.00      0.00      0.00       371\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.91      0.95      0.93      7865\n",
      "\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7640\n",
      "\n",
      "   micro avg       0.97      1.00      0.99      7640\n",
      "   macro avg       0.97      1.00      0.99      7640\n",
      "weighted avg       0.97      1.00      0.99      7640\n",
      "\n",
      "6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7720\n",
      "\n",
      "   micro avg       0.98      1.00      0.99      7720\n",
      "   macro avg       0.98      1.00      0.99      7720\n",
      "weighted avg       0.98      1.00      0.99      7720\n",
      "\n",
      "7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7623\n",
      "\n",
      "   micro avg       0.97      1.00      0.98      7623\n",
      "   macro avg       0.97      1.00      0.98      7623\n",
      "weighted avg       0.97      1.00      0.98      7623\n",
      "\n",
      "8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7865\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       1.00      1.00      1.00      7865\n",
      "weighted avg       1.00      1.00      1.00      7865\n",
      "\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7362\n",
      "\n",
      "   micro avg       0.94      1.00      0.97      7362\n",
      "   macro avg       0.94      1.00      0.97      7362\n",
      "weighted avg       0.94      1.00      0.97      7362\n",
      "\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6964\n",
      "           1       0.73      0.02      0.05       901\n",
      "\n",
      "    accuracy                           0.89      7865\n",
      "   macro avg       0.81      0.51      0.49      7865\n",
      "weighted avg       0.87      0.89      0.84      7865\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      7188\n",
      "           1       0.50      0.00      0.01       677\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.71      0.50      0.48      7865\n",
      "weighted avg       0.88      0.91      0.87      7865\n",
      "\n",
      "12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7747\n",
      "\n",
      "   micro avg       0.98      1.00      0.99      7747\n",
      "   macro avg       0.98      1.00      0.99      7747\n",
      "weighted avg       0.98      1.00      0.99      7747\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7698\n",
      "\n",
      "   micro avg       0.98      1.00      0.99      7698\n",
      "   macro avg       0.98      1.00      0.99      7698\n",
      "weighted avg       0.98      1.00      0.99      7698\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7773\n",
      "\n",
      "   micro avg       0.99      1.00      0.99      7773\n",
      "   macro avg       0.99      1.00      0.99      7773\n",
      "weighted avg       0.99      1.00      0.99      7773\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7583\n",
      "\n",
      "   micro avg       0.96      1.00      0.98      7583\n",
      "   macro avg       0.96      1.00      0.98      7583\n",
      "weighted avg       0.96      1.00      0.98      7583\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7524\n",
      "\n",
      "   micro avg       0.96      1.00      0.98      7524\n",
      "   macro avg       0.96      1.00      0.98      7524\n",
      "weighted avg       0.96      1.00      0.98      7524\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      6845\n",
      "           1       0.00      0.00      0.00      1020\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.44      0.50      0.47      7865\n",
      "weighted avg       0.76      0.87      0.81      7865\n",
      "\n",
      "18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      7334\n",
      "\n",
      "   micro avg       0.93      1.00      0.97      7334\n",
      "   macro avg       0.93      1.00      0.97      7334\n",
      "weighted avg       0.93      1.00      0.97      7334\n",
      "\n",
      "19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7472\n",
      "\n",
      "   micro avg       0.95      1.00      0.97      7472\n",
      "   macro avg       0.95      1.00      0.97      7472\n",
      "weighted avg       0.95      1.00      0.97      7472\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7417\n",
      "\n",
      "   micro avg       0.94      1.00      0.97      7417\n",
      "   macro avg       0.94      1.00      0.97      7417\n",
      "weighted avg       0.94      1.00      0.97      7417\n",
      "\n",
      "21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7685\n",
      "\n",
      "   micro avg       0.98      1.00      0.99      7685\n",
      "   macro avg       0.98      1.00      0.99      7685\n",
      "weighted avg       0.98      1.00      0.99      7685\n",
      "\n",
      "22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7823\n",
      "\n",
      "   micro avg       0.99      1.00      1.00      7823\n",
      "   macro avg       0.99      1.00      1.00      7823\n",
      "weighted avg       0.99      1.00      1.00      7823\n",
      "\n",
      "23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7781\n",
      "\n",
      "   micro avg       0.99      1.00      0.99      7781\n",
      "   macro avg       0.99      1.00      0.99      7781\n",
      "weighted avg       0.99      1.00      0.99      7781\n",
      "\n",
      "24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7832\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      7832\n",
      "   macro avg       1.00      1.00      1.00      7832\n",
      "weighted avg       1.00      1.00      1.00      7832\n",
      "\n",
      "25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7760\n",
      "\n",
      "   micro avg       0.99      1.00      0.99      7760\n",
      "   macro avg       0.99      1.00      0.99      7760\n",
      "weighted avg       0.99      1.00      0.99      7760\n",
      "\n",
      "26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7507\n",
      "\n",
      "   micro avg       0.95      1.00      0.98      7507\n",
      "   macro avg       0.95      1.00      0.98      7507\n",
      "weighted avg       0.95      1.00      0.98      7507\n",
      "\n",
      "27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88      5631\n",
      "           1       0.84      0.41      0.55      2234\n",
      "\n",
      "    accuracy                           0.81      7865\n",
      "   macro avg       0.82      0.69      0.71      7865\n",
      "weighted avg       0.81      0.81      0.79      7865\n",
      "\n",
      "28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      7192\n",
      "           1       0.67      0.00      0.01       673\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.79      0.50      0.48      7865\n",
      "weighted avg       0.89      0.91      0.87      7865\n",
      "\n",
      "29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7128\n",
      "           1       0.69      0.01      0.03       737\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.80      0.51      0.49      7865\n",
      "weighted avg       0.89      0.91      0.86      7865\n",
      "\n",
      "30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7770\n",
      "\n",
      "   micro avg       0.99      1.00      0.99      7770\n",
      "   macro avg       0.99      1.00      0.99      7770\n",
      "weighted avg       0.99      1.00      0.99      7770\n",
      "\n",
      "31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7078\n",
      "           1       0.89      0.08      0.15       787\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.90      0.54      0.55      7865\n",
      "weighted avg       0.91      0.91      0.87      7865\n",
      "\n",
      "32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7718\n",
      "\n",
      "   micro avg       0.98      1.00      0.99      7718\n",
      "   macro avg       0.98      1.00      0.99      7718\n",
      "weighted avg       0.98      1.00      0.99      7718\n",
      "\n",
      "33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7432\n",
      "\n",
      "   micro avg       0.94      1.00      0.97      7432\n",
      "   macro avg       0.94      1.00      0.97      7432\n",
      "weighted avg       0.94      1.00      0.97      7432\n",
      "\n",
      "34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      6372\n",
      "           1       0.79      0.17      0.28      1493\n",
      "\n",
      "    accuracy                           0.83      7865\n",
      "   macro avg       0.81      0.58      0.59      7865\n",
      "weighted avg       0.83      0.83      0.79      7865\n",
      "\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "for col in range(y_pred.shape[1]):\n",
    "\n",
    "    print(classification_report(y_test.iloc[:,col],y_pred[:,col],labels=np.unique(y_pred[:,col])))\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(tokenizer=<function tokenize at 0x00000221C47A9090>)),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('clf', MultiOutputClassifier(estimator=MultinomialNB()))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(tokenizer=<function tokenize at 0x00000221C47A9090>),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'clf': MultiOutputClassifier(estimator=MultinomialNB()),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__alpha': 1.0,\n",
       " 'clf__estimator__class_prior': None,\n",
       " 'clf__estimator__fit_prior': True,\n",
       " 'clf__estimator__force_alpha': 'warn',\n",
       " 'clf__estimator': MultinomialNB(),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        CountVectorizer(tokenizer=&lt;function tokenize at 0x00000221C47A9090&gt;)),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=MultinomialNB()))]),\n",
       "             param_grid={&#x27;clf__estimator__alpha&#x27;: [0.1, 0.5, 1.0, 10.0]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        CountVectorizer(tokenizer=&lt;function tokenize at 0x00000221C47A9090&gt;)),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=MultinomialNB()))]),\n",
       "             param_grid={&#x27;clf__estimator__alpha&#x27;: [0.1, 0.5, 1.0, 10.0]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function tokenize at 0x00000221C47A9090&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultiOutputClassifier(estimator=MultinomialNB()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function tokenize at 0x00000221C47A9090&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=MultinomialNB())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x00000221C47A9090>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=MultinomialNB()))]),\n",
       "             param_grid={'clf__estimator__alpha': [0.1, 0.5, 1.0, 10.0]})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "\n",
    "    'clf__estimator__alpha': [0.1, 0.5]\n",
    "       \n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline,param_grid=parameters)\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'clf__estimator__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Parameters:\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.36      0.47      1844\n",
      "           1       0.82      0.95      0.88      5966\n",
      "           2       0.63      0.22      0.32        55\n",
      "\n",
      "    accuracy                           0.80      7865\n",
      "   macro avg       0.71      0.51      0.56      7865\n",
      "weighted avg       0.79      0.80      0.78      7865\n",
      "\n",
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      6488\n",
      "           1       0.74      0.55      0.63      1377\n",
      "\n",
      "    accuracy                           0.89      7865\n",
      "   macro avg       0.82      0.76      0.78      7865\n",
      "weighted avg       0.88      0.89      0.88      7865\n",
      "\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7838\n",
      "           1       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      4595\n",
      "           1       0.69      0.66      0.68      3270\n",
      "\n",
      "    accuracy                           0.74      7865\n",
      "   macro avg       0.73      0.73      0.73      7865\n",
      "weighted avg       0.73      0.74      0.74      7865\n",
      "\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7239\n",
      "           1       0.60      0.15      0.24       626\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.76      0.57      0.60      7865\n",
      "weighted avg       0.90      0.92      0.90      7865\n",
      "\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      7494\n",
      "           1       0.54      0.14      0.22       371\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.75      0.57      0.60      7865\n",
      "weighted avg       0.94      0.95      0.94      7865\n",
      "\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7640\n",
      "           1       0.00      0.00      0.00       225\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.94      0.97      0.96      7865\n",
      "\n",
      "6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7720\n",
      "           1       0.00      0.00      0.00       145\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      7623\n",
      "           1       0.57      0.22      0.32       242\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.77      0.61      0.65      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7865\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       1.00      1.00      1.00      7865\n",
      "weighted avg       1.00      1.00      1.00      7865\n",
      "\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      7362\n",
      "           1       0.59      0.11      0.18       503\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.77      0.55      0.57      7865\n",
      "weighted avg       0.92      0.94      0.92      7865\n",
      "\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      6964\n",
      "           1       0.71      0.30      0.42       901\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.81      0.64      0.69      7865\n",
      "weighted avg       0.89      0.91      0.89      7865\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7188\n",
      "           1       0.62      0.17      0.27       677\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.77      0.58      0.61      7865\n",
      "weighted avg       0.90      0.92      0.90      7865\n",
      "\n",
      "12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7747\n",
      "           1       0.45      0.08      0.13       118\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.72      0.54      0.56      7865\n",
      "weighted avg       0.98      0.98      0.98      7865\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7698\n",
      "           1       0.57      0.02      0.05       167\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.78      0.51      0.52      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7773\n",
      "           1       0.00      0.00      0.00        92\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7583\n",
      "           1       0.57      0.01      0.03       282\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.77      0.51      0.50      7865\n",
      "weighted avg       0.95      0.96      0.95      7865\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7524\n",
      "           1       0.74      0.09      0.16       341\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.85      0.54      0.57      7865\n",
      "weighted avg       0.95      0.96      0.94      7865\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      6845\n",
      "           1       0.38      0.03      0.05      1020\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.63      0.51      0.49      7865\n",
      "weighted avg       0.81      0.87      0.82      7865\n",
      "\n",
      "18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      7334\n",
      "           1       0.14      0.00      0.01       531\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.54      0.50      0.49      7865\n",
      "weighted avg       0.88      0.93      0.90      7865\n",
      "\n",
      "19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7472\n",
      "           1       0.79      0.06      0.10       393\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.87      0.53      0.54      7865\n",
      "weighted avg       0.94      0.95      0.93      7865\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7417\n",
      "           1       0.64      0.04      0.08       448\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.79      0.52      0.52      7865\n",
      "weighted avg       0.93      0.94      0.92      7865\n",
      "\n",
      "21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7685\n",
      "           1       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.95      0.98      0.97      7865\n",
      "\n",
      "22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7823\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7781\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7832\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7760\n",
      "           1       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.99      0.98      7865\n",
      "\n",
      "26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7507\n",
      "           1       0.00      0.00      0.00       358\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.91      0.95      0.93      7865\n",
      "\n",
      "27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      5631\n",
      "           1       0.74      0.58      0.65      2234\n",
      "\n",
      "    accuracy                           0.82      7865\n",
      "   macro avg       0.79      0.75      0.77      7865\n",
      "weighted avg       0.82      0.82      0.82      7865\n",
      "\n",
      "28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      7192\n",
      "           1       0.72      0.27      0.39       673\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.83      0.63      0.68      7865\n",
      "weighted avg       0.92      0.93      0.91      7865\n",
      "\n",
      "29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      7128\n",
      "           1       0.69      0.35      0.46       737\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.81      0.66      0.71      7865\n",
      "weighted avg       0.91      0.92      0.91      7865\n",
      "\n",
      "30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7770\n",
      "           1       0.25      0.01      0.02        95\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.62      0.51      0.51      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7078\n",
      "           1       0.80      0.35      0.49       787\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.87      0.67      0.72      7865\n",
      "weighted avg       0.92      0.93      0.91      7865\n",
      "\n",
      "32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7718\n",
      "           1       0.67      0.03      0.05       147\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.82      0.51      0.52      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7432\n",
      "           1       0.62      0.02      0.04       433\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.79      0.51      0.51      7865\n",
      "weighted avg       0.93      0.95      0.92      7865\n",
      "\n",
      "34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      6372\n",
      "           1       0.67      0.51      0.58      1493\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.78      0.73      0.75      7865\n",
      "weighted avg       0.85      0.86      0.85      7865\n",
      "\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "pipeline_tuned = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(estimator=MultinomialNB(alpha=0.1)))\n",
    "])\n",
    "\n",
    "pipeline_tuned.fit(X_train , y_train)\n",
    "y_pred_tuned = pipeline_tuned.predict(X_test)\n",
    "\n",
    "for col in range(y_pred_tuned.shape[1]):\n",
    "\n",
    "    print(classification_report(y_test.iloc[:,col],y_pred_tuned[:,col],labels=np.unique(y_pred_tuned[:,col])))\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12076</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15754</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22896</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18351 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "2935         1        1      0            0             0                 0   \n",
       "3395         1        1      0            1             1                 1   \n",
       "4927         1        1      0            0             0                 0   \n",
       "4898         0        0      0            0             0                 0   \n",
       "5237         0        0      0            0             0                 0   \n",
       "...        ...      ...    ...          ...           ...               ...   \n",
       "850          1        1      0            1             0                 0   \n",
       "12076        1        1      0            1             0                 0   \n",
       "15754        1        0      0            0             0                 0   \n",
       "22896        1        0      0            1             0                 0   \n",
       "25001        0        0      0            0             0                 0   \n",
       "\n",
       "       search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "2935                   0         0         0            0  ...            0   \n",
       "3395                   0         0         0            0  ...            0   \n",
       "4927                   0         0         0            0  ...            0   \n",
       "4898                   0         0         0            0  ...            0   \n",
       "5237                   0         0         0            0  ...            0   \n",
       "...                  ...       ...       ...          ...  ...          ...   \n",
       "850                    0         0         0            0  ...            0   \n",
       "12076                  0         0         0            0  ...            0   \n",
       "15754                  0         0         0            0  ...            0   \n",
       "22896                  0         0         0            0  ...            0   \n",
       "25001                  0         0         0            0  ...            0   \n",
       "\n",
       "       other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "2935                      0                0       0      0     0           0   \n",
       "3395                      0                0       0      0     0           0   \n",
       "4927                      0                0       0      0     0           0   \n",
       "4898                      0                0       0      0     0           0   \n",
       "5237                      0                0       0      0     0           0   \n",
       "...                     ...              ...     ...    ...   ...         ...   \n",
       "850                       0                0       0      0     0           0   \n",
       "12076                     0                1       1      0     0           0   \n",
       "15754                     0                1       1      1     0           0   \n",
       "22896                     0                0       0      0     0           0   \n",
       "25001                     0                0       0      0     0           0   \n",
       "\n",
       "       cold  other_weather  direct_report  \n",
       "2935      0              0              0  \n",
       "3395      0              0              1  \n",
       "4927      0              0              1  \n",
       "4898      0              0              0  \n",
       "5237      0              0              0  \n",
       "...     ...            ...            ...  \n",
       "850       0              0              1  \n",
       "12076     0              0              1  \n",
       "15754     0              0              0  \n",
       "22896     0              0              0  \n",
       "25001     0              0              0  \n",
       "\n",
       "[18351 rows x 36 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[174], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m pipeline_SVC \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m      2\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mvect\u001b[39m\u001b[39m'\u001b[39m, CountVectorizer(tokenizer\u001b[39m=\u001b[39mtokenize)),\n\u001b[0;32m      3\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mtfidf\u001b[39m\u001b[39m'\u001b[39m, TfidfTransformer()),\n\u001b[0;32m      4\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mclf\u001b[39m\u001b[39m'\u001b[39m, MultiOutputClassifier(estimator\u001b[39m=\u001b[39mLogisticRegression()))\n\u001b[0;32m      5\u001b[0m ]) \n\u001b[1;32m----> 7\u001b[0m pipeline_SVC\u001b[39m.\u001b[39;49mfit(X_train , y_train)\n\u001b[0;32m      8\u001b[0m y_pred_SVC \u001b[39m=\u001b[39m pipeline_SVC\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(y_pred_SVC\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, Y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m     \u001b[39m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, Y, sample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m [estimator\u001b[39m.\u001b[39mclasses_ \u001b[39mfor\u001b[39;00m estimator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnderlying estimator does not support sample weights.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    217\u001b[0m     delayed(_fit_estimator)(\n\u001b[0;32m    218\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y[:, i], sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_validated\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    220\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m    221\u001b[0m )\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1052\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mc:\\Users\\LocalAdmin\\anaconda3\\envs\\Env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "pipeline_SVC = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(estimator=LogisticRegression()))\n",
    "]) \n",
    "\n",
    "pipeline_SVC.fit(X_train , y_train)\n",
    "y_pred_SVC = pipeline_SVC.predict(X_test)\n",
    "\n",
    "for col in range(y_pred_SVC.shape[1]):\n",
    "\n",
    "    print(classification_report(y_test.iloc[:,col],y_pred_SVC[:,col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
